{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T19:53:58.608337Z",
     "start_time": "2019-10-22T19:53:58.089035Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import Keras and other Deep Learning dependencies\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense, Dropout\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import *\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "import cv2\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from collections import Counter \n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:45:05.739100Z",
     "start_time": "2019-10-22T01:45:05.718112Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "\n",
    "def get_siamese_model(input_shape, similarity_metric='l1', verbose=True):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape,\n",
    "#                     kernel_initializer=initialize_weights, \n",
    "#                     kernel_regularizer=l2(2e-4)))\n",
    "    \n",
    "#     model.add(Conv2D(64, (3,3), activation='relu', input_shape=input_shape,\n",
    "#                     kernel_initializer=initialize_weights, \n",
    "#                     kernel_regularizer=l2(2e-4)))    \n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Dense(input_shape[0]**2, activation='sigmoid', kernel_initializer=initialize_weights,\n",
    "#                     bias_initializer=initialize_bias, \n",
    "#                     kernel_regularizer=l2(1e-3),))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    if similarity_metric == 'l1':\n",
    "        Similarity_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))        \n",
    "    elif siamese_metric == 'l2':\n",
    "        Similarity_layer = Lambda(lambda tensors:K.sqrt(K.square(tensors[0] - tensors[1])))\n",
    "    elif siamese_metric == 'cross': ## TODO\n",
    "        Similarity_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))     \n",
    "        \n",
    "    Similarity_distance = Similarity_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(Similarity_distance)\n",
    "    \n",
    "    # Connect the input with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:45:06.513274Z",
     "start_time": "2019-10-22T01:45:06.507280Z"
    }
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:25:52.507406Z",
     "start_time": "2019-10-23T01:25:52.344501Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Siamese_Loader:\n",
    "    def __init__(self, train_path=None, \n",
    "                 test_path=None, dataset_type = '49kmnist',\n",
    "                 images=None, labels=None, img_channel=1):\n",
    "        \"\"\"\n",
    "        Loads dataset\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        \n",
    "        train_path ... list[train_images, train_labels]\n",
    "        test_path ... list[test_images, test_labels]\n",
    "        \n",
    "        \"\"\"\n",
    "        self.train_images = []\n",
    "        self.train_labels = []\n",
    "        self.train_path = train_path\n",
    "        \n",
    "        self.test_images = []\n",
    "        self.test_labels = []        \n",
    "        self.test_path = test_path\n",
    "        \n",
    "        self.dataset_type = dataset_type        \n",
    "        \n",
    "        if train_path is None and test_path is None:\n",
    "            self.train_images = images[0]\n",
    "            self.train_labels = labels[0]\n",
    "            self.test_images = images[1]\n",
    "            self.test_labels = labels[1] \n",
    "        \n",
    "        else:        \n",
    "            print('Loading Train images')\n",
    "            self.train_images = self._load(self.train_path[0])\n",
    "\n",
    "            print('Loading Test images')\n",
    "            self.test_images = self._load(self.test_path[0])\n",
    "\n",
    "            print('Loading Train labels')\n",
    "            self.train_labels = self._load(self.train_path[1])\n",
    "\n",
    "            print('Loading Test labels')\n",
    "            self.test_labels = self._load(self.test_path[1])\n",
    "\n",
    "        self.train_n_classes = len(np.unique(self.train_labels))\n",
    "        self.test_n_classes = len(np.unique(self.test_labels))\n",
    "        \n",
    "        self.train_shape = self.train_images[0].shape\n",
    "        self.test_shape = self.test_images[0].shape\n",
    "        \n",
    "        self.image_channel = img_channel\n",
    "        \n",
    "    def _load(self, f):\n",
    "        return np.load(f)['arr_0']\n",
    "        \n",
    "    def _get_index(self, labels, i, images):\n",
    "        while True:\n",
    "            idx = np.random.randint(0, len(images))\n",
    "            if labels[idx] == i:\n",
    "                return idx, labels[idx]\n",
    "            \n",
    "    def _get_false_index(self, labels, i, images):\n",
    "        while True:\n",
    "            idx = np.random.randint(0, len(images))\n",
    "            if labels[idx] != i:\n",
    "                return idx, labels[idx]\n",
    "            \n",
    "    def get_batch(self, batch_multiplier = 1, disable_progress_bar = False):\n",
    "        \n",
    "        if type(batch_multiplier) is float:\n",
    "            raise TypeError('batch_multiplier must be an integer')\n",
    "        \n",
    "        n_examples = batch_multiplier*self.train_n_classes\n",
    "        \n",
    "        img_shape = self.train_images[0].shape\n",
    "        pairs = [np.zeros((n_examples, img_shape[0], img_shape[1], self.image_channel)) for i in range(2)]\n",
    "        categs_list = []\n",
    "        targets = []\n",
    "        \n",
    "        images = self.train_images\n",
    "        labels = self.train_labels\n",
    "        n_classes = self.train_n_classes\n",
    "        \n",
    "        k = 0\n",
    "        for i in tqdm_notebook(range(0, n_examples), disable = disable_progress_bar):\n",
    "            img_1 = None\n",
    "            img_2 = None\n",
    "            \n",
    "            i_correto = i % n_classes            \n",
    "            \n",
    "            if i%2 == 0: \n",
    "                idx_1, categ_1 = self._get_index(labels, i_correto, images)\n",
    "                img_1 = self.train_images[idx_1]\n",
    "                idx_2, categ_2 = self._get_index(labels, i_correto, images)\n",
    "                img_2 = images[idx_2]\n",
    "                categs_list.append([categ_1,categ_2])\n",
    "                target = 1\n",
    "                \n",
    "            else:\n",
    "                idx_1, categ_1 = self._get_index(labels, i_correto, images)\n",
    "                img_1 = self.train_images[idx_1]\n",
    "                idx_2, categ_2 = self._get_false_index(labels, i_correto, images)\n",
    "                img_2 = images[idx_2]\n",
    "                categs_list.append([categ_1,categ_2])\n",
    "                target = 0\n",
    "\n",
    "            \n",
    "            pairs[0][k] = img_1.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "            pairs[1][k] = img_2.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "            targets.append(target)\n",
    "            k += 1\n",
    "            \n",
    "        pairs[0] /= 255.\n",
    "        pairs[1] /= 255.\n",
    "        \n",
    "        return pairs, targets, categs_list\n",
    "                    \n",
    "        \n",
    "    def one_shot_task(self, N = 49, tipo = 'train'):\n",
    "        \"\"\"\n",
    "        Create a set of pairs, targets for N-way one shot learning.\n",
    "        \"\"\"\n",
    "        if tipo == 'train':\n",
    "            images = self.train_images\n",
    "            labels = self.train_labels\n",
    "            n_classes = self.train_n_classes\n",
    "        else:\n",
    "            images = self.test_images\n",
    "            labels = self.test_labels\n",
    "            n_classes = self.test_n_classes\n",
    "            \n",
    "        \n",
    "        img_shape = images[0].shape\n",
    "        pairs = [np.zeros((N, img_shape[0], img_shape[1], self.image_channel)) for i in range(2)]\n",
    "        targets = []\n",
    "        k = 0\n",
    "        \n",
    "        i_sorteado = np.random.randint(0,n_classes)\n",
    "        idx_base, categ_base = self._get_index(labels, i_sorteado, images)\n",
    "        img_base = images[idx_base]\n",
    "\n",
    "        idx_pair, categ_pair = self._get_index(labels, i_sorteado, images)\n",
    "        img_pair = images[idx_pair]\n",
    "        \n",
    "        pairs[0][k] = img_base.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "        pairs[1][k] = img_pair.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "        targets.append(1)\n",
    "        \n",
    "        for j in range(1, N):\n",
    "            \n",
    "            idx_pair, categ_pair = self._get_false_index(labels, i_sorteado, images)\n",
    "            img_pair = images[idx_pair]\n",
    "\n",
    "            if categ_base == categ_pair:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "            \n",
    "            k += 1\n",
    "            pairs[0][k] = img_base.reshape((self.train_shape[0],self.train_shape[1],self.image_channel))\n",
    "            pairs[1][k] = img_pair.reshape((self.train_shape[0],self.train_shape[1],self.image_channel))\n",
    "\n",
    "            \n",
    "        \n",
    "        pairs[0] /= 255.\n",
    "        pairs[1] /= 255.\n",
    "        \n",
    "        return pairs, targets\n",
    "    \n",
    "    def test_oneshot(self, model, N, k, verbose=True, tipo = 'test'):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "        for i in range(k):\n",
    "            inputs, targets = self.one_shot_task(N, tipo = tipo)\n",
    "            probs = model.predict(inputs)\n",
    "            probs = 1-probs\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "    \n",
    "    def image_retrieval(self, model, img_search, top_n=5):\n",
    "        images = self.test_images\n",
    "        labels = self.test_labels\n",
    "        n_imgs = len(images)\n",
    "        \n",
    "        img_shape = images[0].shape\n",
    "        pairs = [np.zeros((n_imgs, img_shape[0], img_shape[1], self.image_channel)) for i in range(2)]\n",
    "        targets = []\n",
    "        idx_imgs = []\n",
    "        k = 0\n",
    "        \n",
    "        img_base = img_search\n",
    "        \n",
    "        for i in range(0, n_imgs):            \n",
    "            img_pair = images[i]\n",
    "            pairs[0][k] = img_base.reshape((self.train_shape[0],self.train_shape[1],self.image_channel))\n",
    "            pairs[1][k] = img_pair.reshape((self.train_shape[0],self.train_shape[1],self.image_channel))\n",
    "            idx_imgs.append(i)\n",
    "            k += 1\n",
    "        \n",
    "        pairs[0] /= 255.\n",
    "        pairs[1] /= 255.\n",
    "        \n",
    "        predict = model.predict(pairs)\n",
    "        df = pd.DataFrame(data={'indice':idx_imgs, 'predict':predict.reshape((len(predict)))})\n",
    "        df_N = df.sort_values(by=['predict'])[0:top_n]\n",
    "        ranking_list = df_N['indice'].tolist()\n",
    "        \n",
    "        self.plot_rank(idxs=np.array(ranking_list))\n",
    "    \n",
    "    def plot_rank(self, idxs):\n",
    "        if type(idxs) != np.ndarray:\n",
    "            idxs = np.array([idxs])\n",
    "        fig = plt.figure()\n",
    "        gs = gridspec.GridSpec(1,len(idxs))\n",
    "        for i in range(len(idxs)):\n",
    "            ax = fig.add_subplot(gs[0,i])\n",
    "            ax.imshow(self.test_images[idxs[i]], cmap='gray')\n",
    "            ax.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T21:22:11.785438Z",
     "start_time": "2019-10-22T21:22:11.770445Z"
    }
   },
   "outputs": [],
   "source": [
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc, h , w, _ = X.shape\n",
    "    X = X.reshape(nc, h, w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_oneshot_task(ref, comparativas, x_s = 28, y_s = 28):\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.matshow(ref.reshape(x_s,y_s), cmap='gray')\n",
    "    img = concat_images(comparativas)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "def show_image(img):\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:58:49.552746Z",
     "start_time": "2019-10-18T17:58:49.524759Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(0,10), disable = False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:58:37.504305Z",
     "start_time": "2019-10-17T21:58:37.500310Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# num_classes = 10\n",
    "# epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T15:02:28.189449Z",
     "start_time": "2019-10-18T15:02:28.186451Z"
    }
   },
   "outputs": [],
   "source": [
    "# def load(f):\n",
    "#     return np.load(f)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:58:38.476549Z",
     "start_time": "2019-10-17T21:58:38.471552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# x_train = load('dataset/kuzushiji-mnist/k49-train-imgs.npz')\n",
    "# x_test = load('dataset/kuzushiji-mnist/k49-test-imgs.npz')\n",
    "# y_train = load('dataset/kuzushiji-mnist/k49-train-labels.npz')\n",
    "# y_test = load('dataset/kuzushiji-mnist/k49-test-labels.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:58:39.044902Z",
     "start_time": "2019-10-17T21:58:39.039893Z"
    }
   },
   "outputs": [],
   "source": [
    "# ys = list()\n",
    "# for y in y_train:\n",
    "#     if y not in ys:\n",
    "#         ys.append(y)\n",
    "# print('N classes: {}'.format(len(ys)))\n",
    "# print(len(Counter(y_train).keys()))\n",
    "# np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:08:22.519235Z",
     "start_time": "2019-10-17T22:08:22.335325Z"
    }
   },
   "outputs": [],
   "source": [
    "w = x_train[99]\n",
    "\n",
    "plt.imshow(w, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:13:53.628015Z",
     "start_time": "2019-10-18T19:13:52.969397Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_siamese_model((28, 28, 1), verbose=True)\n",
    "model.compile(loss=contrastive_loss,optimizer=Adam(lr = 0.00006))\n",
    "# model.compile(loss=contrastive_loss,optimizer=Adadelta())\n",
    "# model.compile(loss='binary_crossentropy',optimizer=Adam(lr = 0.00006))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:05:24.732907Z",
     "start_time": "2019-10-18T19:05:23.298733Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loader = Siamese_Loader(train_path=['dataset/kuzushiji-mnist/k49-train-imgs.npz',\n",
    "                                    'dataset/kuzushiji-mnist/k49-train-labels.npz'],\n",
    "                       test_path=['dataset/kuzushiji-mnist/k49-test-imgs.npz',\n",
    "                                  'dataset/kuzushiji-mnist/k49-test-labels.npz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:05:25.927015Z",
     "start_time": "2019-10-18T19:05:25.924016Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_pairs, train_targets = loader.get_batch(batch_multiplier=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:45:59.441607Z",
     "start_time": "2019-10-18T19:45:59.429614Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "test_pairs, test_targets = loader.one_shot_task(N=N, tipo='test')\n",
    "print(test_targets)\n",
    "\n",
    "plot_oneshot_task(test_pairs[0][9], test_pairs[1][:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:18:11.984453Z",
     "start_time": "2019-10-23T01:18:11.975456Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate = 100 # interval for evaluating on one-shot tasks and losses\n",
    "batch_multiplier = 5\n",
    "n_iter = 2000 # 20000\n",
    "best = -1\n",
    "N_way = 10\n",
    "data_path = 'kmodel_weights/'\n",
    "weights_path_2 = 'kmodel_weights/kmodel_weights_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:34:29.191535Z",
     "start_time": "2019-10-19T03:34:22.503428Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"##############################################################\")\n",
    "t_start = time.time()\n",
    "for i in tqdm_notebook(range(1, n_iter)):\n",
    "    \n",
    "    inputs, targets = loader.get_batch(batch_multiplier, disable_progress_bar=True)\n",
    "    \n",
    "    loss=model.train_on_batch(inputs,targets)\n",
    "    \n",
    "    if i % evaluate == 0:\n",
    "        clear_output()\n",
    "        print(\"Time for {0} iterations: {1}\".format(i, time.time()-t_start))\n",
    "        val_acc = loader.test_oneshot(model,N_way,20,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            print(\"Saving weights to: {0} \\n\".format(weights_path_2))\n",
    "            model.save_weights(weights_path_2)\n",
    "            best=val_acc   \n",
    "    \n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
    "        print('---------------------------------------------------------------------------------')\n",
    "\n",
    "        \n",
    "# weights_path_2 = os.path.join(data_path, \"model_weights.h5\")\n",
    "# model.load_weights(weights_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T18:31:39.474335Z",
     "start_time": "2019-10-18T18:29:13.836649Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x=train_pairs, y=train_targets, epochs=2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T18:31:48.152746Z",
     "start_time": "2019-10-18T18:31:48.127762Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_path_fit = 'kmodel_weights/model_weights_2_10.h5'\n",
    "model.save_weights(weight_path_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T18:31:50.860636Z",
     "start_time": "2019-10-18T18:31:50.853643Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:48:50.969775Z",
     "start_time": "2019-10-18T19:48:50.859837Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "test_pairs, test_targets = loader.one_shot_task(N=N, tipo='test')\n",
    "plot_oneshot_task(test_pairs[0][9], test_pairs[1][:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:48:51.502632Z",
     "start_time": "2019-10-18T19:48:51.469649Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = model.predict(x=test_pairs)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T15:58:27.174831Z",
     "start_time": "2019-10-18T15:58:27.171831Z"
    }
   },
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = metrics.roc_curve(test_targets, predict)\n",
    "# metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMNIGLOT - ひらがな"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:44:46.879089Z",
     "start_time": "2019-10-22T01:44:43.651877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alphabet: Japanese_(hiragana)\n",
      "loading alphabet: Japanese_(hiragana)\n"
     ]
    }
   ],
   "source": [
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:44:49.019495Z",
     "start_time": "2019-10-22T01:44:49.013497Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join('dataset/omniglot')\n",
    "train_folder = os.path.join(data_path,'images_train')\n",
    "valpath = os.path.join(data_path,'images_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:44:50.968408Z",
     "start_time": "2019-10-22T01:44:50.686093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training alphabets: \n",
      "\n",
      "['Japanese_(hiragana)']\n",
      "Validation alphabets:\n",
      "\n",
      "['Japanese_(hiragana)']\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, \"pickle/train.pickle\"), \"rb\") as f:\n",
    "    (X, classes) = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, \"pickle/val.pickle\"), \"rb\") as f:\n",
    "    (Xval, val_classes) = pickle.load(f)\n",
    "    \n",
    "print(\"Training alphabets: \\n\")\n",
    "print(list(classes.keys()))\n",
    "print(\"Validation alphabets:\", end=\"\\n\\n\")\n",
    "print(list(val_classes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:44:51.849989Z",
     "start_time": "2019-10-22T01:44:51.840979Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "target = 0\n",
    "for classe in X:    \n",
    "    for img in classe:\n",
    "        x_train.append(img)\n",
    "        y_train.append(target)\n",
    "    target += 1\n",
    "\n",
    "target = 0\n",
    "for classe in Xval:    \n",
    "    for img in classe:\n",
    "        x_test.append(img)\n",
    "        y_test.append(target)\n",
    "    target += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:09:50.118932Z",
     "start_time": "2019-10-22T20:09:50.037564Z"
    }
   },
   "outputs": [],
   "source": [
    "x_imgs = np.asarray([np.asarray(x_train), np.asarray(x_test)])\n",
    "y_lbls = np.asarray([np.asarray(y_train), np.asarray(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:09:50.655666Z",
     "start_time": "2019-10-22T20:09:50.645672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 105, 105)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omni Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:25:58.260139Z",
     "start_time": "2019-10-23T01:25:58.256145Z"
    }
   },
   "outputs": [],
   "source": [
    "omni_loader = Siamese_Loader(images = x_imgs, labels=y_lbls, dataset_type='omniglot_hiragana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:25:58.720889Z",
     "start_time": "2019-10-23T01:25:58.713895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omniglot_hiragana'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni_loader.dataset_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T21:01:27.688681Z",
     "start_time": "2019-10-22T21:01:27.684672Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_hiragana = get_siamese_model((105, 105, 1), verbose=False)\n",
    "# model_hiragana.compile(loss=contrastive_loss,optimizer=Adam(lr = 0.00006))\n",
    "# # model.compile(loss=contrastive_loss,optimizer=Adadelta())\n",
    "# # model.compile(loss='binary_crossentropy',optimizer=Adam(lr = 0.00006))\n",
    "# model_hiragana.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:13:41.775079Z",
     "start_time": "2019-10-22T20:13:40.846013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHQAAADuCAYAAADoZyMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAIn0lEQVR4nO2dTW7tKBBGcauXcDN+3kN6/yu4dxEZv7cH96BlyY0AU1AFxefvSJk4iY05/JrC3o7jCASHv2YngOhCoWBQKBgUCgaFgkGhYFAoGBQKBoWC8bfkj1+v17Hvu1FSiITP5/PnOI6v+LhI6L7v4f1+66WKNLNt20/qOJtcMCgUDAoFg0LBoFAwKBQMCgWDQsGgUDAoFAwKBYNCwaBQMCgUDAoFg0LBoFAwRBELK7FtW/H3qJu0YIXecRWOJJdNbvhP7l2NXgUKvYAglkITrCwVtg8t9Ys1ws6/Wa1/hRVaIiUpJ3m1wdMjhaY4ZZVqb/w7j4LZh0ZIJHkcRFFoguM4xGK9QKEFPDapd1DoDTW11ZN46EFRqilszfzcyNiTzBBYQ7vwJjMECoWDQsGAFeppKjESWKEpPPZ52kAKfWrtDAFUaIon1M4QAIU+uXaGACg0xVNqZwgPEPokmSGAP/obhad1Uvga+jQo1ICZC98UasgMsfB9aEuGaveBIyMIWUMTSGtWbcjKiNpKoQWkAmrEWkul0BssmmxLqXBCpRF7NbRKvYvetxALOyjqkZrK6Nb4oeM4ho504WqoR3r32Uig0AQ5AT2ZP0oqhWYYLVULCm3AQqpWLV1G6DkqvP5YY9VMWkp1L3T2Dq/V1lPdCp0t8oqF1Nw8tfe+3QolbSz3YGFGE2jZUmg/eHBZQ3M36EmmZlok73y4w6XQFJ5kWqAl1Z1QLwOhEiMLlzQ/3AlN4al2WqalND+tFbvcoGgEM/vw0iCpRqoLoSs0syPpGflOE1qbYA+L1RbpsGKKUO0aiVjDa95slmKo0JagK83ztTKzdkqbXxd96BVPTZuXtEjmqC6Eesm4E2/pkTBdaE/mtY4GVxZ2x1ShGhmLLKeFoUKZ+fYs8eiP1EOhYFAoGBQKBoWCQaFgUCgYFAoGhYJBoWBQKBgUCgaFgkGhYFAoGBQKBoWCQaFgUCgYFAoGhYJBoWBQKBgUCsYmCX7etu13COHHLjlEwK/jOL7igyKhxD9scsGgUDAoFAwKBYNCwaBQMCgUDAoFg0LBoFAwKBQMCgWDQsGgUDAoFAwKBYNCwRC96+/1eh37vhslhUj4fD5/UiEoIqH7vof3+62XKtLMtm3J2C42uWCoCUV8kb8F1h+0VXtfburt0itFFG7bNuxDO9drpo73oPoC5PjTFBYJRsIiT9TfaH1X0kfVhKeiKrRWlqZUT98avWNEYR7+EYGzr5XIvzuf9H+Q6RZ6ipGUvlqpp5iWUr1C027Rukybh9Z+Bqvl5lYQeb2/68/5+1a6hMa1oOXbZqVS6l1MC7HImPP49M9NlkpXSQyitDss77lZaG37HzcvT2VUHnTV0JrEpZpkJLEWg6+eczb3oZ4HK639j/T/JH8/akww/euEvUj77BzSgYhVa9M7h15a6KxnxRYyte5FTeiMibz29SQPSFqvbf2octiz3JUex93dh+fvnqqvh5bErTC6rbmP3vNbYrIeujor3wdjisCgUDAoFAwKBYNCwaBQMKY8+vO86lI7//SY9hAGCE3JkwaKjcJbelpQfZabI7cm6k2ql3T0oB6CclIjCiEDpeTyRatgmw2KcolbMfhrpYWFKX2oxvnu6LmepsDRhcFEaOomtMRa1O5S1ENPUxjf84h9P+rroSe5fsLTICiEckHrrV2SmGWtQaKK0NrwiZ4AYivuFuRnFL4eqSp7W0LAGbFa3k9taEtPTe0e5UpGrS21c0aNnl04e/a4TNlO6JXrTroYjXS37tCTXH+YUG99Z8z1NQK57Rw9UlvGD1Oa3Dt697ZYB22FULcjTIMRg0KzGqoZBN0qVbJDvGbjsQa52F+ta5i8NONEs7+07Ht7B3XStFn206pN7l3T5ZHeKPnW+4zzyGXk/CoSW7C6N+3zMgQFDAoFg0LBoFAwKBQMCgWjWWhukm39mI6U6ZqHUlwfFmuvzUJHPfssoRnOgrJQr96HjpSJwKOeFNUEVllcc/Q4QPN6S7+nqIfRL/coDSI1r2m2t0UjwyzXDi3CNiXXs+qz1aL+Qqh/cZP2mqlG5qSCou/QfvmUBirTlp4F3paRai6CQWPUG5+zVJOl17PcUXDS9b7cnqbwWhNqtwjUZrY0c2rOm/p9T0iMVZMrHuVqb2eQZN51lV9rHiyVaYnGaLdp2mIRkpGjtRbU/F9PyIzXefAm7AOOEMr7QVoz5q75vP5d7cCrphbHzaAkYEyjv051W5XRip/jOP6Jj4v70LvNPS1IArVKN1ybhp7+y2vNPDENErMKVaxJQ6mvl0yrStfwiPp2wvhY3KT1NFWtTXrvFoZRaNR+sVBJsHF8LDV/vBtglTYQ5dLX2i/VpEmb6/0ND7T+/v5OSpJmlubAKT537pjHvs8ibU1N7sgS3PMUqmbOOht3z3JLxM3IqEl8z/aE1TETmnveev6O2GBaQyluPK4jFogcCgXDTKjHacITUBFKeX5YvsllYfo/ywtdDesCSKERq9d4089Nar01RHJNK0ZeqwcVobmnQncL0Stk0Oga2xviqjrKPVdSrKLmUte04lpAR6zY5MJSpddU3U4oaZYka5ylc2hxTYtVC3KN572e/y6uSkJXXG6cCI0wxJFItmu0FsDS4kRtwZFUlK4aWrppy/5Rq9DklvY0054bKLoJtL4mJoV1fzNrQKV5P3HQeAnpfTYPiizCOSWs1LSfjEizyXqoZgxt7tzxOXpqbE1a4j5UGpSdO49G2q6YvI3zxHoeem22PI2Yc+cfERqjvuFXuv1Ag5oWQQtpwWlNU2sB7Z62XGkJs9RGmoGSjGuJn21plqX/e8V9GKeEEU2at0jFmMevtswqnFYj3se+BSXFKLmW13l8DUWDQsGgUDCkW/J/hxB+7JJDBPw6juMrPigSSvzDJhcMCgWDQsGgUDAoFAwKBYNCwaBQMCgUjH8BLJw/XxIMww8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 16\n",
    "test_pairs, test_targets = omni_loader.one_shot_task(N=N, tipo='test')\n",
    "\n",
    "plot_oneshot_task(test_pairs[0][9], test_pairs[1][:N], x_s=105, y_s=105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:45:34.327430Z",
     "start_time": "2019-10-22T01:45:34.321433Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate = 100 # interval for evaluating on one-shot tasks and losses\n",
    "batch_multiplier = 4\n",
    "n_iter = 600 # 20000\n",
    "best = -1\n",
    "N_way = 10\n",
    "data_path = 'kmodel_weights/'\n",
    "weights_path_2 = 'kmodel_weights/omni_model_hiragana_weights_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:45:42.927753Z",
     "start_time": "2019-10-22T01:45:42.923754Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Starting training process!\")\n",
    "# print(\"##############################################################\")\n",
    "# t_start = time.time()\n",
    "# for i in tqdm_notebook(range(1, n_iter)):\n",
    "    \n",
    "#     inputs, targets, _ = omni_loader.get_batch(batch_multiplier, disable_progress_bar=True)\n",
    "    \n",
    "#     loss=model_hiragana.train_on_batch(inputs,targets)\n",
    "    \n",
    "#     if i % evaluate == 0:\n",
    "#         clear_output()\n",
    "#         print(\"Time for {0} iterations: {1}\".format(i, time.time()-t_start))\n",
    "#         val_acc = omni_loader.test_oneshot(model_hiragana,N_way,1,verbose=True)\n",
    "#         if val_acc >= best:\n",
    "#             print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "#             print(\"Saving weights to: {0} \\n\".format(weights_path_2))\n",
    "#             model_hiragana.save_weights(weights_path_2)\n",
    "#             best=val_acc   \n",
    "    \n",
    "#         print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
    "#         print('---------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:26:15.115788Z",
     "start_time": "2019-10-23T01:26:15.009833Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs, targets, categs_list = omni_loader.get_batch(batch_multiplier, disable_progress_bar=True)\n",
    "# inputs, targets = loader.get_batch(batch_multiplier, disable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:26:22.749644Z",
     "start_time": "2019-10-23T01:26:22.741649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [1, 29], [2, 2], [3, 40], [4, 4], [5, 29], [6, 6], [7, 19], [8, 8], [9, 33], [10, 10], [11, 17], [12, 12], [13, 35], [14, 14], [15, 0], [16, 16], [17, 11], [18, 18], [19, 31], [20, 20], [21, 25], [22, 22], [23, 22], [24, 24], [25, 22], [26, 26], [27, 33], [28, 28], [29, 11], [30, 30], [31, 35], [32, 32], [33, 25], [34, 34], [35, 6], [36, 36], [37, 4], [38, 38], [39, 34], [40, 40], [41, 36], [42, 42], [43, 0], [44, 44], [45, 24], [46, 46], [47, 17], [48, 48], [49, 12], [50, 50], [51, 36], [0, 0], [1, 42], [2, 2], [3, 15], [4, 4], [5, 11], [6, 6], [7, 24], [8, 8], [9, 10], [10, 10], [11, 33], [12, 12], [13, 43], [14, 14], [15, 30], [16, 16], [17, 2], [18, 18], [19, 47], [20, 20], [21, 10], [22, 22], [23, 9], [24, 24], [25, 15], [26, 26], [27, 48], [28, 28], [29, 51], [30, 30], [31, 50], [32, 32], [33, 35], [34, 34], [35, 20], [36, 36], [37, 23], [38, 38], [39, 1], [40, 40], [41, 43], [42, 42], [43, 0], [44, 44], [45, 47], [46, 46], [47, 3], [48, 48], [49, 44], [50, 50], [51, 5], [0, 0], [1, 8], [2, 2], [3, 31], [4, 4], [5, 43], [6, 6], [7, 48], [8, 8], [9, 46], [10, 10], [11, 36], [12, 12], [13, 16], [14, 14], [15, 51], [16, 16], [17, 41], [18, 18], [19, 2], [20, 20], [21, 28], [22, 22], [23, 39], [24, 24], [25, 42], [26, 26], [27, 31], [28, 28], [29, 7], [30, 30], [31, 36], [32, 32], [33, 13], [34, 34], [35, 6], [36, 36], [37, 16], [38, 38], [39, 34], [40, 40], [41, 23], [42, 42], [43, 0], [44, 44], [45, 33], [46, 46], [47, 19], [48, 48], [49, 40], [50, 50], [51, 3], [0, 0], [1, 34], [2, 2], [3, 45], [4, 4], [5, 11], [6, 6], [7, 47], [8, 8], [9, 48], [10, 10], [11, 44], [12, 12], [13, 15], [14, 14], [15, 29], [16, 16], [17, 21], [18, 18], [19, 26], [20, 20], [21, 48], [22, 22], [23, 28], [24, 24], [25, 6], [26, 26], [27, 17], [28, 28], [29, 2], [30, 30], [31, 37], [32, 32], [33, 36], [34, 34], [35, 49], [36, 36], [37, 10], [38, 38], [39, 45], [40, 40], [41, 37], [42, 42], [43, 32], [44, 44], [45, 8], [46, 46], [47, 46], [48, 48], [49, 16], [50, 50], [51, 32], [0, 0], [1, 28], [2, 2], [3, 19], [4, 4], [5, 22], [6, 6], [7, 18], [8, 8], [9, 18], [10, 10], [11, 19], [12, 12], [13, 48], [14, 14], [15, 25], [16, 16], [17, 4], [18, 18], [19, 45], [20, 20], [21, 40], [22, 22], [23, 36], [24, 24], [25, 31], [26, 26], [27, 29], [28, 28], [29, 48], [30, 30], [31, 25], [32, 32], [33, 31], [34, 34], [35, 3], [36, 36], [37, 35], [38, 38], [39, 19], [40, 40], [41, 10], [42, 42], [43, 15], [44, 44], [45, 18], [46, 46], [47, 7], [48, 48], [49, 12], [50, 50], [51, 49]]\n"
     ]
    }
   ],
   "source": [
    "print(categs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:23:25.719152Z",
     "start_time": "2019-10-23T01:23:25.544247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANn0lEQVR4nO3dX6xlZXnH8e+vM6IFYwA5EJzBDiQT/8TEYk4sStMY0VSpES40gZh2YiaZG1rxT6LQXpDeSWIEmxjTiajTxqAWSSHEaMyIMb3o1DNqFBgRii2MoBxT0MZeVOLTi72OPR3O9MzstdbZ68z7/SQ7e693r733wzrMbz3r3eusk6pCUrt+Z9EFSFosQ0BqnCEgNc4QkBpnCEiNMwSkxo0SAkneluThJI8muWmMz5A0jAx9nkCSHcCPgLcCx4FvA9dX1UODfpCkQewc4T1fDzxaVY8BJPkCcA1w0hC44IILas+ePSOUImnN0aNHf15VSyeOjxECu4An1i0fB/7gxJWSHAAOALz85S9nZWVlhFIkrUny7xuNjzEnkA3GnnfMUVUHq2q5qpaXlp4XTpK2yBghcBy4ZN3ybuDJET5H0gDGCIFvA3uTXJrkLOA64N4RPkfSAAafE6iq55L8OfA1YAfwmap6cOjPkTSMMSYGqaqvAF8Z470lDcszBqXGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxs0dAkkuSXJ/kmNJHkxyYzd+fpKvJ3mkuz9vuHIlDa1PJ/Ac8KGqehVwBXBDklcDNwGHq2ovcLhbljRRc4dAVT1VVd/pHv8ncAzYBVwDHOpWOwRc27dISeMZZE4gyR7gcuAIcFFVPQWzoAAuPMlrDiRZSbKyuro6RBmS5tA7BJK8GPgy8P6q+uWpvq6qDlbVclUtLy0t9S1D0px6hUCSFzALgM9X1d3d8M+SXNw9fzHwdL8SJY2pz7cDAe4AjlXVx9c9dS+wr3u8D7hn/vIkjW1nj9deCfwp8IMk3+vG/hL4KPClJPuBx4F39ytR0pjmDoGq+icgJ3n6qnnft0WzpmocVTXae+vM4BmDUuP6HA5oGxiiy7CbOLPZCUiNMwSkxhkCUuOcE9CmTjav4FzBmcFOQGqcnYDmttk3D3YK24OdgNQ4O4EJGGOPOeZZiFOowS5jOHYCUuPsBM5Qp7qnnELHMI+1uu0I+rMTkBpnJ9C49XvS7doVqB87AalxdgL6rTN9HkEbsxOQGmcnoNO2Wcfg+QHbi52A1DhDQGqchwManC379mInIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI3rHQJJdiT5bpL7uuVLkxxJ8kiSLyY5q3+ZksYyRCdwI3Bs3fKtwG1VtRd4Btg/wGdIGkmvEEiyG/gT4NPdcoA3A3d1qxwCru3zGZLG1bcTuB34MPCbbvmlwLNV9Vy3fBzYtdELkxxIspJkZXV1tWcZkuY1dwgkeQfwdFUdXT+8waob/nJ5VR2squWqWl5aWpq3DEk99bmoyJXAO5NcDbwIeAmzzuDcJDu7bmA38GT/MiWNZe5OoKpurqrdVbUHuA74RlW9B7gfeFe32j7gnt5VShrNGOcJfAT4YJJHmc0R3DHCZ0gayCDXGKyqbwLf7B4/Brx+iPeVND7PGJQa59WGtakx/piIVySeDjsBqXF2AjqpMf+c2Np72xEsnp2A1DhDQGqchwNnuDFb+iF4WLB4dgJS4+wEtqmp7+FP14n/PXYGW8dOQGqcncCAzrS98yI5V7B17ASkxtkJ6LSd6t55iM7IjmB8dgJS4+wEtKl598Jrr7MjmDY7AalxdgKNWOQedKPP9puU6bATkBpnJ7DNbddj5BPrtjNYHDsBqXF2AgParnvl7cRvCYZnJyA1zhDQJFTVae3dkziPMBBDQGqcISA1zhCQGmcIaFJOd25A/RkCUuMMAW1rfkvQnyEgNc4Q0CQ5N7B1DAGpcb1CIMm5Se5K8sMkx5K8Icn5Sb6e5JHu/ryhipU0vL6dwCeAr1bVK4HXAseAm4DDVbUXONwtS5qouUMgyUuAPwLuAKiq/66qZ4FrgEPdaoeAa/sWKWk8fTqBy4BV4LNJvpvk00nOAS6qqqcAuvsLB6hT0kj6hMBO4HXAp6rqcuBXnEbrn+RAkpUkK6urqz3KkNRHnxA4DhyvqiPd8l3MQuFnSS4G6O6f3ujFVXWwqparanlpaalHGZL6mDsEquqnwBNJXtENXQU8BNwL7OvG9gH39KpQ0qj6Xl7sL4DPJzkLeAx4L7Ng+VKS/cDjwLt7foakEfUKgar6HrC8wVNX9XlfSVvHMwalxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1Li+v0UojcI/KLJ17ASkxtkJaFvzD5T0ZycgNc5OQJPiXMDWsxOQGmcISI0zBKTGGQJS45wY1CSc7oSgXw0Ox05AapydgBbKDmDx7ASkxtkJaCE8KWg67ASkxtkJaMv02fs7FzAeOwGpcXYCGp0dwLTZCUiNsxPQ4Jz5317sBKTG9QqBJB9I8mCSB5LcmeRFSS5NciTJI0m+mOSsoYrVtCTZ8DaEqnI+YIvMHQJJdgHvA5ar6jXADuA64FbgtqraCzwD7B+iUEnj6Hs4sBP43SQ7gbOBp4A3A3d1zx8Cru35GZqYIff4J7ID2Hpzh0BV/QT4GPA4s3/8vwCOAs9W1XPdaseBXRu9PsmBJCtJVlZXV+ctQ1JPfQ4HzgOuAS4FXgacA7x9g1U3jPWqOlhVy1W1vLS0NG8Z2kJjdABre347gMXpczjwFuDHVbVaVb8G7gbeCJzbHR4A7Aae7FmjpBH1CYHHgSuSnJ3Z7uEq4CHgfuBd3Tr7gHv6laipGHJv7Z5/OvrMCRxhNgH4HeAH3XsdBD4CfDDJo8BLgTsGqFPSSHqdMVhVtwC3nDD8GPD6Pu+rM4N7+u3BMwalxvm7Azpt7uHPLHYCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAat2kIJPlMkqeTPLBu7PwkX0/ySHd/XjeeJH+T5NEk30/yujGLl9TfqXQCnwPedsLYTcDhqtoLHO6WAd4O7O1uB4BPDVOmpLFsGgJV9S3gP04YvgY41D0+BFy7bvzvauafgXOTXDxUsZKGN++cwEVV9RRAd39hN74LeGLdese7sedJciDJSpKV1dXVOcuQ1NfQE4PZYKw2WrGqDlbVclUtLy0tDVyGpFM1bwj8bK3N7+6f7saPA5esW2838OT85Uka27whcC+wr3u8D7hn3fifdd8SXAH8Yu2wQdI07dxshSR3Am8CLkhyHLgF+CjwpST7gceBd3erfwW4GngU+C/gvSPULGlAm4ZAVV1/kqeu2mDdAm7oW5SkreMZg1LjDAGpcYaA1DhDQGpcZnN5Cy4iWQV+Bfx80bWcgguYfp3WOJztUOep1vh7VfW8M/MmEQIASVaqannRdWxmO9RpjcPZDnX2rdHDAalxhoDUuCmFwMFFF3CKtkOd1jic7VBnrxonMycgaTGm1AlIWgBDQGrcJEIgyduSPNxdoPSmzV8xviSXJLk/ybEkDya5sRvf8CKrC651R5LvJrmvW740yZGuxi8mOWsCNZ6b5K4kP+y26Rumti2TfKD7WT+Q5M4kL5rCthz7Yr8LD4EkO4BPMrtI6auB65O8erFVAfAc8KGqehVwBXBDV9fJLrK6SDcCx9Yt3wrc1tX4DLB/IVX9X58AvlpVrwRey6zeyWzLJLuA9wHLVfUaYAdwHdPYlp9jzIv9VtVCb8AbgK+tW74ZuHnRdW1Q5z3AW4GHgYu7sYuBhxdc1+7uf4I3A/cxu8Tbz4GdG23fBdX4EuDHdBPR68Ynsy353+tjns/sV+zvA/54KtsS2AM8sNm2A/4WuH6j9U52W3gnwGlcnHRRkuwBLgeOcPKLrC7K7cCHgd90yy8Fnq2q57rlKWzPy4BV4LPdYcunk5zDhLZlVf0E+Bizi+Q8BfwCOMr0tuWa3hf7XTOFEDjli5MuQpIXA18G3l9Vv1x0PesleQfwdFUdXT+8waqL3p47gdcBn6qqy5n9nsgUDqN+qzumvga4FHgZcA6z1vpEi96Wmzntn/8UQmCyFydN8gJmAfD5qrq7Gz7ZRVYX4UrgnUn+DfgCs0OC25n9vYe1q0ZNYXseB45X1ZFu+S5moTClbfkW4MdVtVpVvwbuBt7I9LblmsEu9juFEPg2sLebhT2L2WTMvQuuiSQB7gCOVdXH1z11sousbrmqurmqdlfVHmbb7RtV9R7gfuBd3WoLrRGgqn4KPJHkFd3QVcBDTGhbMjsMuCLJ2d3Pfq3GSW3LdYa72O+iJmJOmPS4GvgR8K/AXy26nq6mP2TWRn0f+F53u5rZMfdh4JHu/vxF19rV+ybgvu7xZcC/MLvg6z8AL5xAfb8PrHTb8x+B86a2LYG/Bn4IPAD8PfDCKWxL4E5m8xS/Zran33+ybcfscOCT3b+lHzD7tuP/fX9PG5YaN4XDAUkLZAhIjTMEpMYZAlLjDAGpcYaA1DhDQGrc/wDnep0YTuncCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs[0][2].reshape((105,105)), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T01:23:27.006535Z",
     "start_time": "2019-10-23T01:23:26.818644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs[1][2].reshape((105,105)), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:14:05.572068Z",
     "start_time": "2019-10-22T20:14:05.443142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:46:02.173346Z",
     "start_time": "2019-10-22T01:46:02.171346Z"
    }
   },
   "outputs": [],
   "source": [
    "# p = model_hiragana.predict(inputs)\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:14:09.368178Z",
     "start_time": "2019-10-22T20:14:09.359181Z"
    }
   },
   "outputs": [],
   "source": [
    "x_t, y_t = omni_loader.one_shot_task(N=20, tipo='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:14:09.800726Z",
     "start_time": "2019-10-22T20:14:09.793733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T20:14:11.313796Z",
     "start_time": "2019-10-22T20:14:11.130522Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_oneshot_task(x_t[0][0], x_t[1], x_s=105, y_s=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:47:24.896106Z",
     "start_time": "2019-10-22T01:47:00.388755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1021 22:47:02.090929  9448 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1021 22:47:02.092929  9448 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_hiragana.load_weights('kmodel_weights/gc/omni_model_hiragana_weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41096544196a4f9a91bd604c0ffead63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 39.0%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n = 100\n",
    "for i in tqdm_notebook(range(0, n)):\n",
    "    x_t, y_t = omni_loader.one_shot_task(N=20, tipo='test')\n",
    "    predict = model_hiragana.predict(x_t)\n",
    "    if np.argmin(predict) == 0:\n",
    "        correct += 1\n",
    "print('Acuracia: {}%'.format((correct/n)*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:52:41.809115Z",
     "start_time": "2019-10-22T01:52:41.061544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_hiragana.predict(x_t)\n",
    "np.argmin(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T01:54:46.654364Z",
     "start_time": "2019-10-22T01:54:46.640371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39794412]\n",
      " [0.5464858 ]\n",
      " [0.6967162 ]\n",
      " [0.8662625 ]\n",
      " [0.90881   ]\n",
      " [0.9234793 ]\n",
      " [0.9398962 ]\n",
      " [0.97940993]\n",
      " [0.98412955]\n",
      " [0.98460686]\n",
      " [0.9926179 ]\n",
      " [0.993678  ]\n",
      " [0.99888843]\n",
      " [0.9989736 ]\n",
      " [0.9989736 ]\n",
      " [0.999514  ]\n",
      " [0.99978113]\n",
      " [0.9998758 ]\n",
      " [0.99992347]\n",
      " [0.9999392 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(predict, kind='mergesort', axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T02:40:15.334868Z",
     "start_time": "2019-10-22T02:40:15.328872Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'indice':is_, \n",
    "                        'predict':predict.reshape((len(predict)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T02:40:43.839884Z",
     "start_time": "2019-10-22T02:40:43.827905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.397944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.546486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.696716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.866262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.908810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    indice   predict\n",
       "3        3  0.397944\n",
       "1        1  0.546486\n",
       "16      16  0.696716\n",
       "15      15  0.866262\n",
       "17      17  0.908810"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['predict'])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T02:40:52.750700Z",
     "start_time": "2019-10-22T02:40:52.742703Z"
    }
   },
   "outputs": [],
   "source": [
    "b = df.sort_values(by=['predict'])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T21:19:57.945534Z",
     "start_time": "2019-10-22T21:19:57.673003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAE8UlEQVR4nO3d267cKBCFYXeU939l52KrJYftA1Dlog7/J83VZDqmwKsx0J7Pvu8bAMDGn9UXAACVELoAYIjQBQBDhC4AGCJ0AcAQoQsAhv4+/Psq58k+A3+WmpyjLr9Rk9/K14SZLgAYInQBwNDT8gKEPp+fpwx++TfnW79R1BteMdMFAEOELtJhllvT7FORNZYX4BoBipEw/Xw+7scMoRtYOxi9DzbgbRHuAUIXcO6tx+YIAdU6XnOU5YSWaegeixSxwz1hlpubRaBEeBTftuuxHeHaz7CRlkDUwYe1GDdrhFleiHLe9WqGMjpz6W2n93pAjj7OxXXongVVlEciqbO2f9sddS0L/SqM8aqWhS6/NJKjFsA1r3tIKqFrMfPyVLQ77XVqdPzxM5jlAve83yPLlxeihOlK1EjubrkG8d0Frbd+Xhq63orhndfHJc+8z3ogFylwt00pdHsbVjE09n3nxjdCnWvo7WevGbN8eaGSKicv3jYTru2XX9Z+iHK0ctRIn3tvu8vQzXxzzAZvxVmc5gmXbGMq83gYmclG/GWmy9DNRnuJIcLAsvRUjwwBlaENUu17FyIG7rYRughq9gaLcmMSsv976rco/bpthO4S0rXdt35S7I32dUeow+wmUablk9Enl2jtJXSNSJYYpLOeTDfkKM8zRq0vz0r9m6Gt7kM3645/T7uk5w8rv7siupljmNm1be1pu8ex7j50M7mb7b5x9jDDC58los2KRq6x2i/sJE+J3uqyPHSrhcExeKuszeKcZn8yNuIwCd2rx9zR/77awDoGdLW2S0Wb5Y6IvpEkNbIs57E2qqH79qw1cwA9HehHv6x1qxq2khBNu7yg/W7ctsgZbqIMbcA6BO5cmz3WSRy6T2Fyd56wV/Tgnbl2749IHt1tUkauYdXAzUoUujODYTZA2w2oKAPvqUYR2+RN5C/kJ5W/fLO2Xe3/BpypKFpmZyiZQ8TKvu/lj8zBZ78vPzKWldYjIV9m4572CiLUtGf8RHt59whJWHpfjlSb6WrJ8EgxErjMxmSeah1xDJ216ftWreM/I58RWcQ+vLM0dO9+1he10Gx62OmtdfQ+WPXOjlWiXncvlhcUzQbu1a/UoofFm7J+uWksGRw/I/oGrWRZrmeTesX9tmSme/ZIHT1sPIdA9Nq2PNda4q5ds+/cwI92WaZnieYtaqEraUDkxwmtN9hzo9R2NYbaUxjZWWTB3Xlui79ftLzQ7hKOPMpc7TBGGmDRr78q6c64tqwzdylpHWZOMVjUXrymO3s8I3pgWdwoGkecIj9FVEDgvstjPVU20iSvKzyKuuivcc13dZupS9abWbJZ6Z3WNWb4oo3QX7PcndON5o3BIf3MDDddBfRTTWpHxr5BMTKQrk4xVPvBwNnpgraevbPdrDPc7N7qp5nPjfrEGYX6Od1qnSVZd+35Qjlbuuk5czh7TbD3Zj9JflixYvxUGLNufhwxsiHnsWN6zsKOvgZz5O+UflZE0dv45uy2whNiVG5C94rXG+tuOUX7mMpoDbzWTEPmtmmiTn6xkSYkPbyufXNwswG+uZrpRg6M3o1EzTZGrhdQlavQzYAgBHCH5QUAMEToAoAhQhcADBG6AGCI0AUAQ4QuABgidAHAEKELAIY+HOYHADvMdAHAEKELAIYIXQAwROgCgCFCFwAMEboAYOgf9a7J3nXzHeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "omni_loader.plot_rank(np.array(b['indice'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T21:24:33.302410Z",
     "start_time": "2019-10-22T21:24:33.110518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(x_t[0][0].reshape((105,105)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T22:07:52.569649Z",
     "start_time": "2019-10-22T22:07:33.997422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "omni_loader.image_retrieval(model=model_hiragana, img_search=x_t[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(self, batch_multiplier = 1, disable_progress_bar = False):\n",
    "        \n",
    "        if type(batch_multiplier) is float:\n",
    "            raise TypeError('batch_multiplier must be an integer')\n",
    "        \n",
    "        n_examples = batch_multiplier*self.train_n_classes\n",
    "        \n",
    "        img_shape = self.train_images[0].shape\n",
    "        pairs = [np.zeros((n_examples, img_shape[0], img_shape[1], self.image_channel)) for i in range(2)]\n",
    "        categs_list = []\n",
    "        targets = []\n",
    "        \n",
    "        images = self.train_images\n",
    "        labels = self.train_labels\n",
    "        n_classes = self.train_n_classes\n",
    "        \n",
    "        k = 0\n",
    "        for i in tqdm_notebook(range(0, batch_multiplier), disable = disable_progress_bar):\n",
    "            img_1 = None\n",
    "            img_2 = None\n",
    "            \n",
    "            for j in range(0, n_classes):\n",
    "                idx_1, categ_1 = self._get_index(labels, j, images)\n",
    "                img_1 = self.train_images[idx_1]\n",
    "                idx_2, categ_2 = self._get_index(labels, j, images)\n",
    "                img_2 = images[idx_2]\n",
    "                categs_list.append([categ_1,categ_2])\n",
    "                target = 1\n",
    "                \n",
    "                pairs[0][k] = img_1.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "                pairs[1][k] = img_2.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "                targets.append(target)\n",
    "                k += 1\n",
    "            \n",
    "            for j_ in range(0, n_classes):\n",
    "                idx_1, categ_1 = self._get_index(labels, j_, images)\n",
    "                img_1 = self.train_images[idx_1]\n",
    "                idx_2, categ_2 = self._get_false_index(labels, j_, images)\n",
    "                img_2 = images[idx_2]\n",
    "                categs_list.append([categ_1,categ_2])\n",
    "                target = 0\n",
    "                \n",
    "                pairs[0][k] = img_1.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "                pairs[1][k] = img_2.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "                targets.append(target)\n",
    "                k += 1\n",
    "\n",
    "            \n",
    "        pairs[0] /= 255.\n",
    "        pairs[1] /= 255.\n",
    "        \n",
    "        return pairs, targets, categs_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
