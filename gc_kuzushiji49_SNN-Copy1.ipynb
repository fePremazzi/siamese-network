{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:53:50.359356Z",
     "start_time": "2019-10-19T03:52:47.291462Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import Keras and other Deep Learning dependencies\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense, Dropout\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import *\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "import cv2\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from collections import Counter \n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:58.926409Z",
     "start_time": "2019-10-19T03:55:58.897426Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "\n",
    "def get_siamese_model(input_shape, similarity_metric='l1', verbose=True):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape,\n",
    "#                     kernel_initializer=initialize_weights, \n",
    "#                     kernel_regularizer=l2(2e-4)))\n",
    "    \n",
    "#     model.add(Conv2D(64, (3,3), activation='relu', input_shape=input_shape,\n",
    "#                     kernel_initializer=initialize_weights, \n",
    "#                     kernel_regularizer=l2(2e-4)))    \n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Dense(input_shape[0]**2, activation='sigmoid', kernel_initializer=initialize_weights,\n",
    "#                     bias_initializer=initialize_bias, \n",
    "#                     kernel_regularizer=l2(1e-3),))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    if similarity_metric == 'l1':\n",
    "        Similarity_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))        \n",
    "    elif siamese_metric == 'l2':\n",
    "        Similarity_layer = Lambda(lambda tensors:K.sqrt(K.square(tensors[0] - tensors[1])))\n",
    "    elif siamese_metric == 'cross': ## TODO\n",
    "        Similarity_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))     \n",
    "        \n",
    "    Similarity_distance = Similarity_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(Similarity_distance)\n",
    "    \n",
    "    # Connect the input with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:00.043925Z",
     "start_time": "2019-10-19T03:56:00.034929Z"
    }
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:00.871846Z",
     "start_time": "2019-10-19T03:56:00.822873Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Siamese_Loader:\n",
    "    def __init__(self, train_path=None, \n",
    "                 test_path=None, dataset_type = '49kmnist',\n",
    "                 images=None, labels=None, img_channel=1):\n",
    "        \"\"\"\n",
    "        Loads dataset\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        \n",
    "        train_path ... list[train_images, train_labels]\n",
    "        test_path ... list[test_images, test_labels]\n",
    "        \n",
    "        \"\"\"\n",
    "        self.train_images = []\n",
    "        self.train_labels = []\n",
    "        self.train_path = train_path\n",
    "        \n",
    "        self.test_images = []\n",
    "        self.test_labels = []        \n",
    "        self.test_path = test_path\n",
    "        \n",
    "        self.dataset_type = dataset_type        \n",
    "        \n",
    "        if train_path is None and test_path is None:\n",
    "            self.train_images = images[0]\n",
    "            self.train_labels = labels[0]\n",
    "            self.test_images = images[1]\n",
    "            self.test_labels = labels[1] \n",
    "        \n",
    "        else:        \n",
    "            print('Loading Train images')\n",
    "            self.train_images = self._load(self.train_path[0])\n",
    "\n",
    "            print('Loading Test images')\n",
    "            self.test_images = self._load(self.test_path[0])\n",
    "\n",
    "            print('Loading Train labels')\n",
    "            self.train_labels = self._load(self.train_path[1])\n",
    "\n",
    "            print('Loading Test labels')\n",
    "            self.test_labels = self._load(self.test_path[1])\n",
    "\n",
    "        self.train_n_classes = len(np.unique(self.train_labels))\n",
    "        self.test_n_classes = len(np.unique(self.test_labels))\n",
    "        \n",
    "        self.train_shape = self.train_images[0].shape\n",
    "        self.test_shape = self.test_images[0].shape\n",
    "        \n",
    "        self.image_channel = img_channel\n",
    "        \n",
    "    def _load(self, f):\n",
    "        return np.load(f)['arr_0']\n",
    "        \n",
    "    def _get_index(self, labels, i, images):\n",
    "        while True:\n",
    "            idx = np.random.randint(0, len(images))\n",
    "            if labels[idx] == i:\n",
    "                return idx, labels[idx]\n",
    "            \n",
    "    def _get_false_index(self, labels, i, images):\n",
    "        while True:\n",
    "            idx = np.random.randint(0, len(images))\n",
    "            if labels[idx] != i:\n",
    "                return idx, labels[idx]\n",
    "            \n",
    "    def get_batch(self, batch_multiplier = 1, disable_progress_bar = False):\n",
    "        \n",
    "        if type(batch_multiplier) is float:\n",
    "            raise TypeError('batch_multiplier must be an integer')\n",
    "        \n",
    "        n_examples = batch_multiplier*self.train_n_classes\n",
    "        \n",
    "        img_shape = self.train_images[0].shape\n",
    "        pairs = [np.zeros((n_examples, img_shape[0], img_shape[1], self.image_channel)) for i in range(2)]\n",
    "        targets = []\n",
    "        \n",
    "        images = self.train_images\n",
    "        labels = self.train_labels\n",
    "        n_classes = self.train_n_classes\n",
    "        \n",
    "        k = 0\n",
    "        for i in tqdm_notebook(range(0, n_examples), disable = disable_progress_bar):\n",
    "            img_1 = None\n",
    "            img_2 = None\n",
    "            \n",
    "            i_correto = i % n_classes            \n",
    "            \n",
    "            if i%2 == 0: \n",
    "                idx_1, categ_1 = self._get_index(labels, i_correto, images)\n",
    "                img_1 = self.train_images[idx_1]\n",
    "                idx_2, categ_2 = self._get_index(labels, i_correto, images)\n",
    "                img_2 = images[idx_2]\n",
    "                target = 1\n",
    "                \n",
    "            else:\n",
    "                idx_1, categ_1 = self._get_index(labels, i_correto, images)\n",
    "                img_1 = self.train_images[idx_1]\n",
    "                idx_2, categ_2 = self._get_false_index(labels, i_correto, images)\n",
    "                img_2 = images[idx_2]\n",
    "                target = 0\n",
    "\n",
    "            \n",
    "            pairs[0][k] = img_1.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "            pairs[1][k] = img_2.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "            targets.append(target)\n",
    "            k += 1\n",
    "            \n",
    "        pairs[0] /= 255.\n",
    "        pairs[1] /= 255.\n",
    "        \n",
    "        return pairs, targets\n",
    "                    \n",
    "        \n",
    "    def one_shot_task(self, N = 49, tipo = 'train'):\n",
    "        \"\"\"\n",
    "        Create a set of pairs, targets for N-way one shot learning.\n",
    "        \"\"\"\n",
    "        if tipo == 'train':\n",
    "            images = self.train_images\n",
    "            labels = self.train_labels\n",
    "            n_classes = self.train_n_classes\n",
    "        else:\n",
    "            images = self.test_images\n",
    "            labels = self.test_labels\n",
    "            n_classes = self.test_n_classes\n",
    "            \n",
    "        \n",
    "        img_shape = images[0].shape\n",
    "        pairs = [np.zeros((N, img_shape[0], img_shape[1], self.image_channel)) for i in range(2)]\n",
    "        targets = []\n",
    "        k = 0\n",
    "        \n",
    "        i_sorteado = np.random.randint(0,n_classes)\n",
    "        idx_base, categ_base = self._get_index(labels, i_sorteado, images)\n",
    "        img_base = images[idx_base]\n",
    "\n",
    "        idx_pair, categ_pair = self._get_index(labels, i_sorteado, images)\n",
    "        img_pair = images[idx_pair]\n",
    "        \n",
    "        pairs[0][k] = img_base.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "        pairs[1][k] = img_pair.reshape((self.train_shape[0], self.train_shape[1], self.image_channel))\n",
    "        targets.append(1)\n",
    "        \n",
    "        for j in range(1, N):\n",
    "            \n",
    "            idx_pair, categ_pair = self._get_false_index(labels, i_sorteado, images)\n",
    "            img_pair = images[idx_pair]\n",
    "\n",
    "            if categ_base == categ_pair:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "            \n",
    "            k += 1\n",
    "            pairs[0][k] = img_base.reshape((self.train_shape[0],self.train_shape[1],self.image_channel))\n",
    "            pairs[1][k] = img_pair.reshape((self.train_shape[0],self.train_shape[1],self.image_channel))\n",
    "\n",
    "            \n",
    "        \n",
    "        pairs[0] /= 255.\n",
    "        pairs[1] /= 255.\n",
    "        \n",
    "        return pairs, targets\n",
    "    \n",
    "    def test_oneshot(self, model, N, k, verbose=True, tipo = 'test'):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "        for i in range(k):\n",
    "            inputs, targets = self.one_shot_task(N, tipo = tipo)\n",
    "            probs = model.predict(inputs)\n",
    "            probs = 1-probs\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "        return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:02.058029Z",
     "start_time": "2019-10-19T03:56:02.044037Z"
    }
   },
   "outputs": [],
   "source": [
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc, h , w, _ = X.shape\n",
    "    X = X.reshape(nc, h, w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_oneshot_task(ref, comparativas, x_s = 28, y_s = 28):\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.matshow(ref.reshape(x_s,y_s), cmap='gray')\n",
    "    img = concat_images(comparativas)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:58:49.552746Z",
     "start_time": "2019-10-18T17:58:49.524759Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(0,10), disable = False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:58:37.504305Z",
     "start_time": "2019-10-17T21:58:37.500310Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# num_classes = 10\n",
    "# epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T15:02:28.189449Z",
     "start_time": "2019-10-18T15:02:28.186451Z"
    }
   },
   "outputs": [],
   "source": [
    "# def load(f):\n",
    "#     return np.load(f)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:58:38.476549Z",
     "start_time": "2019-10-17T21:58:38.471552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# x_train = load('dataset/kuzushiji-mnist/k49-train-imgs.npz')\n",
    "# x_test = load('dataset/kuzushiji-mnist/k49-test-imgs.npz')\n",
    "# y_train = load('dataset/kuzushiji-mnist/k49-train-labels.npz')\n",
    "# y_test = load('dataset/kuzushiji-mnist/k49-test-labels.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T21:58:39.044902Z",
     "start_time": "2019-10-17T21:58:39.039893Z"
    }
   },
   "outputs": [],
   "source": [
    "# ys = list()\n",
    "# for y in y_train:\n",
    "#     if y not in ys:\n",
    "#         ys.append(y)\n",
    "# print('N classes: {}'.format(len(ys)))\n",
    "# print(len(Counter(y_train).keys()))\n",
    "# np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:08:22.519235Z",
     "start_time": "2019-10-17T22:08:22.335325Z"
    }
   },
   "outputs": [],
   "source": [
    "w = x_train[99]\n",
    "\n",
    "plt.imshow(w, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:13:53.628015Z",
     "start_time": "2019-10-18T19:13:52.969397Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_siamese_model((28, 28, 1), verbose=True)\n",
    "model.compile(loss=contrastive_loss,optimizer=Adam(lr = 0.00006))\n",
    "# model.compile(loss=contrastive_loss,optimizer=Adadelta())\n",
    "# model.compile(loss='binary_crossentropy',optimizer=Adam(lr = 0.00006))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:05:24.732907Z",
     "start_time": "2019-10-18T19:05:23.298733Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loader = Siamese_Loader(train_path=['dataset/kuzushiji-mnist/k49-train-imgs.npz',\n",
    "                                    'dataset/kuzushiji-mnist/k49-train-labels.npz'],\n",
    "                       test_path=['dataset/kuzushiji-mnist/k49-test-imgs.npz',\n",
    "                                  'dataset/kuzushiji-mnist/k49-test-labels.npz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:05:25.927015Z",
     "start_time": "2019-10-18T19:05:25.924016Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_pairs, train_targets = loader.get_batch(batch_multiplier=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:45:59.441607Z",
     "start_time": "2019-10-18T19:45:59.429614Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "test_pairs, test_targets = loader.one_shot_task(N=N, tipo='test')\n",
    "print(test_targets)\n",
    "\n",
    "plot_oneshot_task(test_pairs[0][9], test_pairs[1][:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:14:00.603227Z",
     "start_time": "2019-10-18T19:14:00.598230Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate = 100 # interval for evaluating on one-shot tasks and losses\n",
    "batch_multiplier = 4\n",
    "n_iter = 2000 # 20000\n",
    "best = -1\n",
    "N_way = 10\n",
    "data_path = 'kmodel_weights/'\n",
    "weights_path_2 = 'kmodel_weights/kmodel_weights_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:34:29.191535Z",
     "start_time": "2019-10-19T03:34:22.503428Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"##############################################################\")\n",
    "t_start = time.time()\n",
    "for i in tqdm_notebook(range(1, n_iter)):\n",
    "    \n",
    "    inputs, targets = loader.get_batch(batch_multiplier, disable_progress_bar=True)\n",
    "    \n",
    "    loss=model.train_on_batch(inputs,targets)\n",
    "    \n",
    "    if i % evaluate == 0:\n",
    "        clear_output()\n",
    "        print(\"Time for {0} iterations: {1}\".format(i, time.time()-t_start))\n",
    "        val_acc = loader.test_oneshot(model,N_way,20,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            print(\"Saving weights to: {0} \\n\".format(weights_path_2))\n",
    "            model.save_weights(weights_path_2)\n",
    "            best=val_acc   \n",
    "    \n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
    "        print('---------------------------------------------------------------------------------')\n",
    "\n",
    "        \n",
    "# weights_path_2 = os.path.join(data_path, \"model_weights.h5\")\n",
    "# model.load_weights(weights_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T18:31:39.474335Z",
     "start_time": "2019-10-18T18:29:13.836649Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x=train_pairs, y=train_targets, epochs=2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T18:31:48.152746Z",
     "start_time": "2019-10-18T18:31:48.127762Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_path_fit = 'kmodel_weights/model_weights_2_10.h5'\n",
    "model.save_weights(weight_path_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T18:31:50.860636Z",
     "start_time": "2019-10-18T18:31:50.853643Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:48:50.969775Z",
     "start_time": "2019-10-18T19:48:50.859837Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "test_pairs, test_targets = loader.one_shot_task(N=N, tipo='test')\n",
    "plot_oneshot_task(test_pairs[0][9], test_pairs[1][:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T19:48:51.502632Z",
     "start_time": "2019-10-18T19:48:51.469649Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = model.predict(x=test_pairs)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T15:58:27.174831Z",
     "start_time": "2019-10-18T15:58:27.171831Z"
    }
   },
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = metrics.roc_curve(test_targets, predict)\n",
    "# metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:52:47.288514Z",
     "start_time": "2019-10-19T03:52:30.828369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alphabet: Japanese_(hiragana)\n",
      "loading alphabet: Japanese_(hiragana)\n"
     ]
    }
   ],
   "source": [
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:40.396799Z",
     "start_time": "2019-10-19T03:55:40.391802Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join('dataset/omniglot')\n",
    "train_folder = os.path.join(data_path,'images_train')\n",
    "valpath = os.path.join(data_path,'images_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:42.717141Z",
     "start_time": "2019-10-19T03:55:42.673165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training alphabets: \n",
      "\n",
      "['Japanese_(hiragana)']\n",
      "Validation alphabets:\n",
      "\n",
      "['Japanese_(hiragana)']\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, \"pickle/train.pickle\"), \"rb\") as f:\n",
    "    (X, classes) = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, \"pickle/val.pickle\"), \"rb\") as f:\n",
    "    (Xval, val_classes) = pickle.load(f)\n",
    "    \n",
    "print(\"Training alphabets: \\n\")\n",
    "print(list(classes.keys()))\n",
    "print(\"Validation alphabets:\", end=\"\\n\\n\")\n",
    "print(list(val_classes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:44.941405Z",
     "start_time": "2019-10-19T03:55:44.932409Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "target = 0\n",
    "for classe in X:    \n",
    "    for img in classe:\n",
    "        x_train.append(img)\n",
    "        y_train.append(target)\n",
    "    target += 1\n",
    "\n",
    "target = 0\n",
    "for classe in Xval:    \n",
    "    for img in classe:\n",
    "        x_test.append(img)\n",
    "        y_test.append(target)\n",
    "    target += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:46.716698Z",
     "start_time": "2019-10-19T03:55:46.217701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:48.785501Z",
     "start_time": "2019-10-19T03:55:48.772496Z"
    }
   },
   "outputs": [],
   "source": [
    "x_imgs = np.asarray([np.asarray(x_train), np.asarray(x_test)])\n",
    "y_lbls = np.asarray([np.asarray(y_train), np.asarray(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:55:49.538467Z",
     "start_time": "2019-10-19T03:55:49.532467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 105, 105)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:11.034401Z",
     "start_time": "2019-10-19T03:56:11.028406Z"
    }
   },
   "outputs": [],
   "source": [
    "omni_loader = Siamese_Loader(images = x_imgs, labels=y_lbls, dataset_type='omniglot_hiragana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:12.271088Z",
     "start_time": "2019-10-19T03:56:12.264090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omniglot_hiragana'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni_loader.dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:22.731978Z",
     "start_time": "2019-10-19T03:56:18.985135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 4096)         38947648    input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 4096)         0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            4097        lambda_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_hiragana = get_siamese_model((105, 105, 1), verbose=False)\n",
    "model_hiragana.compile(loss=contrastive_loss,optimizer=Adam(lr = 0.00006))\n",
    "# model.compile(loss=contrastive_loss,optimizer=Adadelta())\n",
    "# model.compile(loss='binary_crossentropy',optimizer=Adam(lr = 0.00006))\n",
    "model_hiragana.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 16\n",
    "test_pairs, test_targets = omni_loader.one_shot_task(N=N, tipo='test')\n",
    "\n",
    "plot_oneshot_task(test_pairs[0][9], test_pairs[1][:N], x_s=105, y_s=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:56:25.203361Z",
     "start_time": "2019-10-19T03:56:25.198363Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate = 100 # interval for evaluating on one-shot tasks and losses\n",
    "batch_multiplier = 4\n",
    "n_iter = 600 # 20000\n",
    "best = -1\n",
    "N_way = 10\n",
    "data_path = 'kmodel_weights/'\n",
    "weights_path_2 = 'kmodel_weights/omni_model_hiragana_weights_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T04:01:01.112989Z",
     "start_time": "2019-10-19T03:56:27.281505Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 500 iterations: 167.83492922782898\n",
      "Evaluating model on 1 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 100.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 100.0, previous best: 100.0\n",
      "Saving weights to: kmodel_weights/omni_model_hiragana_weights_1.h5 \n",
      "\n",
      "iteration 500, training loss: 0.18,\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"##############################################################\")\n",
    "t_start = time.time()\n",
    "for i in tqdm_notebook(range(1, n_iter)):\n",
    "    \n",
    "    inputs, targets = omni_loader.get_batch(batch_multiplier, disable_progress_bar=True)\n",
    "    \n",
    "    loss=model_hiragana.train_on_batch(inputs,targets)\n",
    "    \n",
    "    if i % evaluate == 0:\n",
    "        clear_output()\n",
    "        print(\"Time for {0} iterations: {1}\".format(i, time.time()-t_start))\n",
    "        val_acc = omni_loader.test_oneshot(model_hiragana,N_way,1,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            print(\"Saving weights to: {0} \\n\".format(weights_path_2))\n",
    "            model_hiragana.save_weights(weights_path_2)\n",
    "            best=val_acc   \n",
    "    \n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
    "        print('---------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:34:48.681135Z",
     "start_time": "2019-10-19T03:34:43.880743Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs, targets = omni_loader.get_batch(batch_multiplier, disable_progress_bar=True)\n",
    "# inputs, targets = loader.get_batch(batch_multiplier, disable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T03:34:50.544242Z",
     "start_time": "2019-10-19T03:34:50.520254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs[0][2].reshape((105,105)), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs[1][2].reshape((105,105)), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07819474]\n",
      " [0.9530854 ]\n",
      " [0.00471979]\n",
      " [0.99907255]\n",
      " [0.04967433]\n",
      " [0.9995208 ]\n",
      " [0.14416355]\n",
      " [0.99980664]\n",
      " [0.07096747]\n",
      " [0.9995147 ]\n",
      " [0.02558032]\n",
      " [0.9999473 ]\n",
      " [0.00893933]\n",
      " [0.99999523]\n",
      " [0.01011994]\n",
      " [0.9999938 ]\n",
      " [0.04875603]\n",
      " [0.9111043 ]\n",
      " [0.0675894 ]\n",
      " [0.9869051 ]\n",
      " [0.01314721]\n",
      " [0.9986696 ]\n",
      " [0.20201814]\n",
      " [0.99978113]\n",
      " [0.13327274]\n",
      " [0.9999932 ]\n",
      " [0.03907815]\n",
      " [0.99993205]\n",
      " [0.07820347]\n",
      " [0.999329  ]\n",
      " [0.05746487]\n",
      " [0.9934052 ]\n",
      " [0.6195356 ]\n",
      " [0.9999873 ]\n",
      " [0.07284221]\n",
      " [0.9917108 ]\n",
      " [0.01084524]\n",
      " [0.90852106]\n",
      " [0.08468094]\n",
      " [0.9413328 ]\n",
      " [0.08053303]\n",
      " [0.95314986]\n",
      " [0.0828864 ]\n",
      " [0.9473704 ]\n",
      " [0.6195356 ]\n",
      " [0.9575542 ]\n",
      " [0.03507495]\n",
      " [0.9985305 ]\n",
      " [0.09593564]\n",
      " [0.99667823]\n",
      " [0.01655519]\n",
      " [0.99528897]\n",
      " [0.6195356 ]\n",
      " [0.94656044]\n",
      " [0.04084885]\n",
      " [0.999748  ]\n",
      " [0.11611375]\n",
      " [0.8384712 ]\n",
      " [0.06497297]\n",
      " [0.9999058 ]\n",
      " [0.03461832]\n",
      " [0.9456352 ]\n",
      " [0.6195356 ]\n",
      " [0.9999484 ]\n",
      " [0.12096438]\n",
      " [0.9999871 ]\n",
      " [0.01392686]\n",
      " [0.99985325]\n",
      " [0.01762906]\n",
      " [0.98819435]\n",
      " [0.07451889]\n",
      " [0.9999763 ]\n",
      " [0.03840047]\n",
      " [0.999503  ]\n",
      " [0.10556713]\n",
      " [0.9995985 ]\n",
      " [0.13682607]\n",
      " [0.99991   ]\n",
      " [0.03418598]\n",
      " [0.9999323 ]\n",
      " [0.03115249]\n",
      " [0.9998496 ]\n",
      " [0.02724373]\n",
      " [0.9732128 ]\n",
      " [0.04476494]\n",
      " [0.99721   ]\n",
      " [0.04434958]\n",
      " [0.88490415]\n",
      " [0.06175011]\n",
      " [0.99602   ]\n",
      " [0.03693032]\n",
      " [0.86950475]\n",
      " [0.01255304]\n",
      " [0.9957197 ]\n",
      " [0.03196573]\n",
      " [0.9997557 ]\n",
      " [0.6195356 ]\n",
      " [0.99971676]\n",
      " [0.07040021]\n",
      " [0.99965847]\n",
      " [0.05255172]\n",
      " [0.99993956]\n",
      " [0.02995867]\n",
      " [0.9999943 ]\n",
      " [0.07244042]\n",
      " [0.9324101 ]\n",
      " [0.03419352]\n",
      " [0.9998097 ]\n",
      " [0.0562315 ]\n",
      " [0.9998553 ]\n",
      " [0.03678647]\n",
      " [0.9839836 ]\n",
      " [0.03844717]\n",
      " [0.99853516]\n",
      " [0.02248856]\n",
      " [0.99979085]\n",
      " [0.13321063]\n",
      " [0.6508045 ]\n",
      " [0.08439144]\n",
      " [0.9977666 ]\n",
      " [0.01473436]\n",
      " [0.9874883 ]\n",
      " [0.09700274]\n",
      " [0.9907809 ]\n",
      " [0.09005314]\n",
      " [0.70875245]\n",
      " [0.03608063]\n",
      " [0.9911254 ]\n",
      " [0.04190764]\n",
      " [0.9988178 ]\n",
      " [0.01375738]\n",
      " [0.99988365]\n",
      " [0.10200888]\n",
      " [0.93546355]\n",
      " [0.02752802]\n",
      " [0.99123645]\n",
      " [0.03001869]\n",
      " [0.99979174]\n",
      " [0.00713485]\n",
      " [0.9986403 ]\n",
      " [0.01084524]\n",
      " [0.9998126 ]\n",
      " [0.04675019]\n",
      " [0.99999905]\n",
      " [0.00631693]\n",
      " [0.9418616 ]\n",
      " [0.03655592]\n",
      " [0.9999973 ]\n",
      " [0.09516987]\n",
      " [0.9980165 ]\n",
      " [0.02714014]\n",
      " [0.98641354]\n",
      " [0.10429478]\n",
      " [0.9997368 ]\n",
      " [0.05005211]\n",
      " [0.9998939 ]\n",
      " [0.00956145]\n",
      " [0.999807  ]\n",
      " [0.02769074]\n",
      " [0.9987112 ]\n",
      " [0.02668077]\n",
      " [0.9631897 ]\n",
      " [0.08569044]\n",
      " [0.9976555 ]\n",
      " [0.08347836]\n",
      " [0.9930085 ]\n",
      " [0.04627365]\n",
      " [0.9804547 ]\n",
      " [0.01900038]\n",
      " [0.9978812 ]\n",
      " [0.02591732]\n",
      " [0.99999845]\n",
      " [0.0075255 ]\n",
      " [0.99668694]\n",
      " [0.0653393 ]\n",
      " [0.9503038 ]\n",
      " [0.02991652]\n",
      " [0.9998302 ]\n",
      " [0.16435885]\n",
      " [0.9995936 ]\n",
      " [0.05215469]\n",
      " [0.99948084]\n",
      " [0.07038304]\n",
      " [0.9936198 ]\n",
      " [0.12120646]\n",
      " [0.99999326]\n",
      " [0.09729534]\n",
      " [0.99948215]\n",
      " [0.07983524]\n",
      " [0.96853113]\n",
      " [0.01967841]\n",
      " [0.97772527]\n",
      " [0.01364979]\n",
      " [0.92607796]\n",
      " [0.07619661]\n",
      " [0.99996567]\n",
      " [0.08241591]\n",
      " [0.91395897]\n",
      " [0.00279802]\n",
      " [0.89927745]\n",
      " [0.27866393]\n",
      " [0.98220253]\n",
      " [0.05400437]\n",
      " [0.9999765 ]\n",
      " [0.01495674]\n",
      " [0.881086  ]\n",
      " [0.10897797]\n",
      " [0.99784493]]\n"
     ]
    }
   ],
   "source": [
    "p = model_hiragana.predict(inputs)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t = omni_loader.one_shot_task(N=20, tipo='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_oneshot_task(x_t[0][0], x_t[1], x_s=105, y_s=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "predict = model_hiragana.predict(x_t)\n",
    "print(np.argmin(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41096544196a4f9a91bd604c0ffead63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 39.0%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n = 100\n",
    "for i in tqdm_notebook(range(0, n)):\n",
    "    x_t, y_t = omni_loader.one_shot_task(N=20, tipo='test')\n",
    "    predict = model_hiragana.predict(x_t)\n",
    "    if np.argmin(predict) == 0:\n",
    "        correct += 1\n",
    "print('Acuracia: {}%'.format((correct/n)*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
